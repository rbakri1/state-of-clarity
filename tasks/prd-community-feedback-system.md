# PRD: Community Feedback System (Epic 3.4)

## Introduction

The Community Feedback System enables users to provide structured feedback on policy briefs through voting, source suggestions, error reporting, and edit proposals. This creates a feedback loop that helps identify high-quality content and surfaces opportunities for improvement.

**Problem:** Briefs are generated by AI and may contain errors, miss important sources, or have unclear arguments. Users have no way to signal quality or contribute improvements.

**Solution:** Four feedback mechanisms (vote, suggest source, spot error, propose edit) with public aggregate counts but private contributor identity. All feedback requires login. AI pre-screens submissions with human review for flagged items. Feedback is informational for MVP (no automatic brief updates).

## Goals

- Enable users to upvote/downvote briefs to surface quality content
- Allow users to suggest missing sources with political lean metadata
- Let users report factual errors or outdated information
- Support edit proposals for unclear or misleading content
- Show aggregate feedback counts publicly while keeping contributor identity private
- AI pre-screen feedback with human review queue for flagged items
- Require authentication for all feedback types

## User Stories

### US-001: Create feedback database schema

**Description:** As a developer, I need database tables to store all feedback types.

**Acceptance Criteria:**
- [ ] Create brief_votes table: id, brief_id, user_id, vote_type ('up' | 'down'), created_at
- [ ] Create source_suggestions table: id, brief_id, user_id, url, title, publisher, political_lean, notes, status ('pending' | 'approved' | 'rejected' | 'flagged'), ai_screening_result (JSONB), created_at
- [ ] Create error_reports table: id, brief_id, user_id, error_type ('factual' | 'outdated' | 'misleading' | 'other'), description, location_hint, status, ai_screening_result, created_at
- [ ] Create edit_proposals table: id, brief_id, user_id, section ('summary' | 'narrative' | 'structured_data'), original_text, proposed_text, rationale, status, ai_screening_result, created_at
- [ ] Add unique constraint on brief_votes (brief_id, user_id) - one vote per user per brief
- [ ] Add RLS: users can insert/update own feedback, select own feedback, admins can select all
- [ ] Add TypeScript types to Database interface
- [ ] Typecheck passes

---

### US-002: Create vote API endpoints

**Description:** As a developer, I need APIs to handle voting on briefs.

**Acceptance Criteria:**
- [ ] Create /app/api/briefs/[id]/vote/route.ts
- [ ] POST: Create or update vote (body: { vote_type: 'up' | 'down' })
- [ ] DELETE: Remove user's vote
- [ ] GET: Return user's current vote (if any) and aggregate counts
- [ ] Require authentication for all methods
- [ ] Return { upvotes, downvotes, userVote } on GET
- [ ] Typecheck passes

---

### US-003: Create vote button component

**Description:** As a reader, I want to upvote or downvote a brief.

**Acceptance Criteria:**
- [ ] Create /app/components/VoteButtons.tsx
- [ ] Display upvote and downvote buttons with counts
- [ ] Filled icon state when user has voted that direction
- [ ] Clicking same vote again removes the vote (toggle behavior)
- [ ] Clicking opposite vote switches the vote
- [ ] Optimistic UI updates
- [ ] Show sign-in prompt if user not authenticated
- [ ] Typecheck passes
- [ ] Verify in browser using dev-browser skill

---

### US-004: Integrate vote buttons into brief page

**Description:** As a reader, I want to see and use vote buttons on the brief page.

**Acceptance Criteria:**
- [ ] Add VoteButtons to brief header near clarity score
- [ ] Fetch initial vote state and counts on page load
- [ ] Votes update counts in real-time (optimistic)
- [ ] Layout doesn't shift when counts change
- [ ] Typecheck passes
- [ ] Verify in browser using dev-browser skill

---

### US-005: Create suggest source modal

**Description:** As a reader, I want to suggest a missing source for a brief.

**Acceptance Criteria:**
- [ ] Create /app/components/SuggestSourceModal.tsx
- [ ] Form fields: URL (required), Title (optional), Publisher (optional), Political Lean (dropdown: Left/Center-Left/Center/Center-Right/Right/Unknown), Notes (optional textarea)
- [ ] URL validation (must be valid URL format)
- [ ] Submit button disabled until URL provided
- [ ] Modal closes on successful submit with success toast
- [ ] Show sign-in prompt if not authenticated
- [ ] Typecheck passes
- [ ] Verify in browser using dev-browser skill

---

### US-006: Create suggest source API endpoint

**Description:** As a developer, I need an API to handle source suggestions.

**Acceptance Criteria:**
- [ ] Create /app/api/briefs/[id]/suggest-source/route.ts
- [ ] POST: Create source suggestion with status 'pending'
- [ ] Require authentication
- [ ] Validate URL format
- [ ] Store user_id, brief_id, and all form fields
- [ ] Trigger AI screening (async, don't block response)
- [ ] Return success with suggestion id
- [ ] Typecheck passes

---

### US-007: Create spot error modal

**Description:** As a reader, I want to report an error in a brief.

**Acceptance Criteria:**
- [ ] Create /app/components/SpotErrorModal.tsx
- [ ] Form fields: Error Type (dropdown: Factual Error, Outdated Info, Misleading Statement, Other), Description (required textarea), Location Hint (optional - "Which section?")
- [ ] Description has min 20 character requirement
- [ ] Submit disabled until type selected and description provided
- [ ] Modal closes on success with thank you toast
- [ ] Show sign-in prompt if not authenticated
- [ ] Typecheck passes
- [ ] Verify in browser using dev-browser skill

---

### US-008: Create spot error API endpoint

**Description:** As a developer, I need an API to handle error reports.

**Acceptance Criteria:**
- [ ] Create /app/api/briefs/[id]/report-error/route.ts
- [ ] POST: Create error report with status 'pending'
- [ ] Require authentication
- [ ] Validate description length >= 20 chars
- [ ] Store all form fields
- [ ] Trigger AI screening (async)
- [ ] Return success with report id
- [ ] Typecheck passes

---

### US-009: Create propose edit modal

**Description:** As a reader, I want to propose an edit to improve a brief.

**Acceptance Criteria:**
- [ ] Create /app/components/ProposeEditModal.tsx
- [ ] Form fields: Section (dropdown: Summary, Narrative, Structured Data), Original Text (textarea - what's wrong), Proposed Text (textarea - suggested fix), Rationale (textarea - why this is better)
- [ ] All fields required
- [ ] Each textarea min 20 characters
- [ ] Submit disabled until all fields valid
- [ ] Modal closes on success with thank you toast
- [ ] Show sign-in prompt if not authenticated
- [ ] Typecheck passes
- [ ] Verify in browser using dev-browser skill

---

### US-010: Create propose edit API endpoint

**Description:** As a developer, I need an API to handle edit proposals.

**Acceptance Criteria:**
- [ ] Create /app/api/briefs/[id]/propose-edit/route.ts
- [ ] POST: Create edit proposal with status 'pending'
- [ ] Require authentication
- [ ] Validate all fields present and min length
- [ ] Store all form fields
- [ ] Trigger AI screening (async)
- [ ] Return success with proposal id
- [ ] Typecheck passes

---

### US-011: Create feedback action buttons

**Description:** As a reader, I want easy access to all feedback options.

**Acceptance Criteria:**
- [ ] Create /app/components/FeedbackActions.tsx
- [ ] Display 3 buttons: "Suggest Source", "Spot Error", "Propose Edit"
- [ ] Each button opens corresponding modal
- [ ] Buttons use subtle styling (secondary/outline variant)
- [ ] Show as icon-only on mobile, icon+text on desktop
- [ ] Typecheck passes
- [ ] Verify in browser using dev-browser skill

---

### US-012: Integrate feedback actions into brief page

**Description:** As a reader, I want feedback options visible on the brief page.

**Acceptance Criteria:**
- [ ] Add FeedbackActions component to brief page (near bottom or in sidebar)
- [ ] Section header: "Help improve this brief"
- [ ] Brief explanation text: "Suggest sources, report errors, or propose edits"
- [ ] All modals work when triggered from this section
- [ ] Typecheck passes
- [ ] Verify in browser using dev-browser skill

---

### US-013: Create AI screening service

**Description:** As a developer, I need AI to pre-screen feedback for spam/abuse.

**Acceptance Criteria:**
- [ ] Create /lib/services/feedback-screening.ts
- [ ] Function: screenFeedback(type, content): Promise<ScreeningResult>
- [ ] ScreeningResult: { approved: boolean, flagged: boolean, reason?: string, confidence: number }
- [ ] Use Claude Haiku for cost efficiency
- [ ] Prompt checks for: spam, abuse, off-topic, low-effort, duplicate
- [ ] If flagged, set status to 'flagged' for human review
- [ ] If approved and confidence > 0.9, set status to 'approved' (auto-approve high confidence)
- [ ] Otherwise status stays 'pending'
- [ ] Typecheck passes

---

### US-014: Apply AI screening to source suggestions

**Description:** As a system, I need source suggestions screened by AI.

**Acceptance Criteria:**
- [ ] After source suggestion created, call screenFeedback('source', { url, notes })
- [ ] Update source_suggestions.ai_screening_result with result
- [ ] Update status based on screening result
- [ ] If URL appears to be spam or unrelated, flag for review
- [ ] Typecheck passes

---

### US-015: Apply AI screening to error reports

**Description:** As a system, I need error reports screened by AI.

**Acceptance Criteria:**
- [ ] After error report created, call screenFeedback('error', { error_type, description })
- [ ] Update error_reports.ai_screening_result with result
- [ ] Update status based on screening result
- [ ] Flag vague or potentially abusive reports
- [ ] Typecheck passes

---

### US-016: Apply AI screening to edit proposals

**Description:** As a system, I need edit proposals screened by AI.

**Acceptance Criteria:**
- [ ] After edit proposal created, call screenFeedback('edit', { original_text, proposed_text, rationale })
- [ ] Update edit_proposals.ai_screening_result with result
- [ ] Update status based on screening result
- [ ] Flag low-effort or potentially harmful edits
- [ ] Typecheck passes

---

### US-017: Create admin feedback review page

**Description:** As an admin, I want to review pending and flagged feedback.

**Acceptance Criteria:**
- [ ] Create /app/admin/feedback/page.tsx (protected admin route)
- [ ] Show tabs: All, Pending, Flagged, Approved, Rejected
- [ ] List feedback items with: type, brief title, user email, created_at, status, AI result
- [ ] Each item expandable to see full details
- [ ] Typecheck passes
- [ ] Verify in browser using dev-browser skill

---

### US-018: Add admin actions to feedback items

**Description:** As an admin, I want to approve or reject feedback.

**Acceptance Criteria:**
- [ ] Add Approve and Reject buttons to each feedback item
- [ ] Create /app/api/admin/feedback/[type]/[id]/route.ts
- [ ] PATCH: Update status to 'approved' or 'rejected'
- [ ] Require admin role (check user metadata or admin table)
- [ ] Show success toast on action
- [ ] Item moves to appropriate tab after action
- [ ] Typecheck passes
- [ ] Verify in browser using dev-browser skill

---

### US-019: Show feedback counts on brief cards

**Description:** As a visitor, I want to see brief popularity on homepage cards.

**Acceptance Criteria:**
- [ ] Add upvote count to brief cards on homepage
- [ ] Display as "ðŸ‘ 42" or similar compact format
- [ ] Fetch counts via existing brief query (add vote aggregation)
- [ ] Don't show if count is 0
- [ ] Typecheck passes
- [ ] Verify in browser using dev-browser skill

---

### US-020: Create user feedback history page

**Description:** As a user, I want to see feedback I've submitted.

**Acceptance Criteria:**
- [ ] Create /app/profile/feedback/page.tsx (protected route)
- [ ] List all user's feedback: votes, source suggestions, error reports, edit proposals
- [ ] Show status of each item (pending, approved, rejected, flagged)
- [ ] Link each item to the relevant brief
- [ ] Group by type or show in chronological order
- [ ] Typecheck passes
- [ ] Verify in browser using dev-browser skill

## Functional Requirements

- FR-1: Store votes, source suggestions, error reports, and edit proposals in database
- FR-2: Enforce one vote per user per brief
- FR-3: Show aggregate vote counts publicly, keep voter identity private
- FR-4: Require authentication for all feedback types
- FR-5: Validate feedback inputs (URL format, min lengths)
- FR-6: AI pre-screen all non-vote feedback for spam/abuse
- FR-7: Auto-approve high-confidence AI screenings
- FR-8: Flag suspicious feedback for human review
- FR-9: Provide admin interface for reviewing and actioning feedback
- FR-10: Show user's own feedback history
- FR-11: Display vote counts on brief cards

## Non-Goals

- Automatic brief updates based on feedback (informational only for MVP)
- Public display of who submitted feedback (privacy-first)
- Reputation points for feedback (Epic 5.2)
- Threading/replies on feedback items
- Email notifications for feedback status changes (post-MVP)
- Bulk moderation actions (post-MVP)

## Design Considerations

**Vote Buttons:**
- Thumbs up/down or arrow icons
- Subtle when not voted, filled when voted
- Count next to each button
- Compact horizontal layout

**Feedback Modals:**
- Clean, focused forms
- Clear field labels and validation messages
- Success state before closing

**Admin Review:**
- Dense table layout for efficiency
- Quick action buttons
- AI screening result visible for context

## Technical Considerations

**AI Screening Prompt:**
```
Review this user feedback for a policy brief:
Type: {type}
Content: {content}

Check for:
1. Spam or promotional content
2. Abusive or offensive language
3. Off-topic or irrelevant feedback
4. Low-effort submissions (too vague to be useful)

Respond with JSON:
{
  "approved": boolean,
  "flagged": boolean,
  "reason": "explanation if flagged",
  "confidence": 0.0-1.0
}
```

**Database Indexes:**
- brief_votes: (brief_id, user_id) unique
- source_suggestions: (brief_id, status)
- error_reports: (brief_id, status)
- edit_proposals: (brief_id, status)

**Vote Aggregation:**
- Cache vote counts on brief record or compute via COUNT
- Update optimistically on client

## Success Metrics

- 10% of brief viewers submit at least one vote
- 2% of viewers submit detailed feedback (source, error, edit)
- AI screening catches >90% of spam with <5% false positives
- Admin review queue stays under 50 items
- Average time to review flagged item <24 hours

## Open Questions

1. Should we notify users when their feedback is approved/rejected?
2. Should approved source suggestions be visible on the brief (even without incorporation)?
3. Do we need rate limiting on feedback submissions?
